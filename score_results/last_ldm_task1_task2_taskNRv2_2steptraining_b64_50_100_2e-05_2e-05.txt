corpus_bleu_score = [0.10580507722350437, 0.010298252742649089, 0.0011461733380467235, 7.608058340262083e-80]
sacre_blue_score = {'score': 0.13220563491820872, 'counts': [5109, 66, 23, 0], 'totals': [35699, 34301, 32903, 31505], 'precisions': [14.311325247205804, 0.19241421532899916, 0.06990244050694465, 0.0015870496746548167], 'bp': 1.0, 'sys_len': 35699, 'ref_len': 32886}
rouge_scores = {'rouge-1': {'r': 0.07542279166940428, 'p': 0.06683427893457856, 'f': 0.06800997271002131}, 'rouge-2': {'r': 0.00031110283946433366, 'p': 0.0002815270716784157, 'f': 0.00027876400062208846}, 'rouge-l': {'r': 0.068239741220956, 'p': 0.05958786983943643, 'f': 0.06101213649331098}}
wer_scores = 1.1447528435510408
cer_scores = 1.1154426274465383
corpus_bleu_score_with_tf = [0, 0, 0, 0]
sacre_blue_score_with_tf = {'score': 0.0, 'counts': [0, 0, 0, 0], 'totals': [0, 0, 0, 0], 'precisions': [0.0, 0.0, 0.0, 0.0], 'bp': 0.0, 'sys_len': 0, 'ref_len': 32886}
rouge_scores_with_tf = Hypothesis is empty
wer_scores_with_tf = 1.0
cer_scores_with_tf = 1.0
